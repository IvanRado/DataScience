{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winning Jeopardy\n",
    "\n",
    "In this project, we'll be doing some brief analysis on historical data from the popular game show Jeopardy. In particular, we'll be looking to answer some questions as to how one might go about maximizing their chances of winning, and if any insight can be gleaned from past episodes.\n",
    "\n",
    "To begin, we'll do some preliminary investigation and cleaning of the data. This includes formatting the column names, converting the date strings to datetime objects and converting the value column from a series of objects to a series of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Show Number    Air Date      Round                         Category  Value  \\\n",
      "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
      "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
      "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
      "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
      "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
      "\n",
      "                                            Question      Answer  \n",
      "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
      "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
      "2  The city of Yuma in this state has a record av...     Arizona  \n",
      "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
      "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "jeopardy = pd.read_csv('jeopardy.csv')\n",
    "print(jeopardy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
      "       ' Question', ' Answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(jeopardy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardize column names\n",
    "new_columns = []\n",
    "for col in jeopardy.columns:\n",
    "    if col[0] == ' ':\n",
    "        col = col.replace(' ', '', 1)\n",
    "    new_columns.append(col)\n",
    "\n",
    "jeopardy.columns = new_columns\n",
    "\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(string):\n",
    "    string = string.lower()\n",
    "    string = re.sub('[^A-Za-z0-9\\s]', '', string)\n",
    "    return string\n",
    "\n",
    "clean_question = jeopardy['Question'].apply(normalize_string)\n",
    "clean_answer = jeopardy['Answer'].apply(normalize_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    $200\n",
      "1    $200\n",
      "2    $200\n",
      "3    $200\n",
      "4    $200\n",
      "Name: Value, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(jeopardy['Value'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    200\n",
      "1    200\n",
      "2    200\n",
      "3    200\n",
      "4    200\n",
      "Name: Value, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def normalize_dollars(string):\n",
    "    string = re.sub('[^A-Za-z0-9\\s]', '', string)\n",
    "    try: \n",
    "        clean = int(string)\n",
    "    except Exception:\n",
    "        clean = 0\n",
    "        \n",
    "    return clean\n",
    "\n",
    "clean_value = jeopardy['Value'].apply(normalize_dollars)\n",
    "print(clean_value.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['clean_question'] = clean_question\n",
    "jeopardy['clean_answer'] = clean_answer\n",
    "jeopardy['clean_value'] = clean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['Air Date'] = pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at this historical data, we want to consider a few questions to see if we can learn anything from previous contestants. The questions we'll be looking to answer here are:\n",
    "\n",
    "  1. How often does the answer appear in the question?\n",
    "  2. How much overlap is there between terms in new questions and terms in old questions? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcs(row):\n",
    "    split_answer = row['clean_answer'].split(' ')\n",
    "    split_question = row['clean_question'].split(' ')\n",
    "    match_count = 0\n",
    "    \n",
    "    if 'the' in split_answer:\n",
    "        split_answer.remove('the')\n",
    "    \n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    \n",
    "    for item in split_answer:\n",
    "        if item in split_question:\n",
    "            match_count += 1\n",
    "            \n",
    "    return match_count/len(split_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.060493257069335914\n"
     ]
    }
   ],
   "source": [
    "answer_in_question = jeopardy.apply(funcs, axis = 1)\n",
    "means = answer_in_question.mean()\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our analysis reveals that the answer only appears in the question about 6% of the time, meaning that we can't rely on the question giving us a strong indication of what the answer entails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6876260592169776\n"
     ]
    }
   ],
   "source": [
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "jeopardy = jeopardy.sort_values('Air Date')\n",
    "\n",
    "for index, row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question'].split(' ')\n",
    "    split_question = [r for r in split_question if len(r) >= 6]\n",
    "    match_count = 0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "        \n",
    "    for word in split_question:\n",
    "        terms_used.add(word)\n",
    "    \n",
    "    if len(split_question) > 0:\n",
    "        match_count = match_count/len(split_question)\n",
    "    \n",
    "    question_overlap.append(match_count)\n",
    "    \n",
    "jeopardy['question_overlap'] = question_overlap\n",
    "mean_overlap = jeopardy['question_overlap'].mean()\n",
    "\n",
    "print(mean_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some significant overlap, about 68.7%, between terms in old and new questions. This does not speak of the question itself or the ordering, but the fact that there is a high overlap may indicate that there are some topics which are more likely to reappear in future episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 3), (0, 1), (2, 1), (0, 1), (3, 14)]\n"
     ]
    }
   ],
   "source": [
    "def check_value(row):\n",
    "    value = 0\n",
    "    if row['clean_value'] > 800:\n",
    "        value = 1\n",
    "    \n",
    "    return value\n",
    "\n",
    "jeopardy['high_value'] = jeopardy.apply(check_value, axis = 1)\n",
    "\n",
    "def word_occurence(word):\n",
    "    high_count = 0\n",
    "    low_count = 0\n",
    "    for index, row in jeopardy.iterrows():\n",
    "        if word in row['clean_question'].split(' '):\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "            \n",
    "    return high_count, low_count\n",
    "\n",
    "observed_expected = []\n",
    "comparison_terms = list(terms_used)[0:5]\n",
    "\n",
    "for word in comparison_terms:\n",
    "    observed_expected.append(word_occurence(word))\n",
    "    \n",
    "print(observed_expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Power_divergenceResult(statistic=1.205888538380652, pvalue=0.27214791766901714), Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469), Power_divergenceResult(statistic=2.1177104383031944, pvalue=0.14560406868263753), Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469), Power_divergenceResult(statistic=1.0102851115076668, pvalue=0.314834544813388)]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "high_value_count = jeopardy[jeopardy['high_value'] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy['high_value'] == 0].shape[0]\n",
    "\n",
    "chi_squared = []\n",
    "\n",
    "for item in observed_expected:\n",
    "    total = item[0] + item[1]\n",
    "    total_prop = total/jeopardy.shape[0]\n",
    "    expected_high = total_prop * high_value_count\n",
    "    expected_low = total_prop * low_value_count\n",
    "    \n",
    "    expected = np.array([expected_high, expected_low])\n",
    "    observed = np.array([item[0], item[1]])\n",
    "    \n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "\n",
    "print(chi_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Chi-Squared Results\n",
    "\n",
    "There doesn't seem to be a significant difference in usage between high value and low value rows. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
